<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>shoji.io.chunked_io API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>shoji.io.chunked_io</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import List, Tuple, Any, Union
import numpy as np
import fdb
import blosc
from numpy.ma.core import MaskedArray
import logging

&#34;&#34;&#34;
# Chunked storage API

Shoji uses FoundationDB, a scalable and resilient key-value database, as its backing store. In order to bridge the mismatch between
a key-value store and a tensor database, the chunked storage API layer implements an N-dimensional compressed chunk storage layer.

Chunks are arbitrary numpy arrays, although they are intended to store chunks of N-dimensional tensors. Chunks are 
addressed using N-tuples of ordered integers, such as (0, 10, 9). Addresses can be viewed simply as abstract pointers, 
although they are intended to correspond to chunk offsets along each dimension of an N-dimensional tensor.

Chunks are stored in a FoundationDB subspace and under a specific key prefix (intended to store a single tensor). All chunks that 
are in the same subspace and using the same key prefix must use addresses of the same length (intended to correspond to the rank of a tensor). 

The chunked storage API layer provides functions for reading and writing sets of chunks using on-the-fly compression.

Note that the chunk address space need not be densely filled. That is, if a chunk exists at (10, 9, 3), this does not mean that 
chunks must exist at (9, 8, 1) or any other address. Reading from an empty address returns None. Writing to a non-empty address
silently overwrites the existing chunk.

&#34;&#34;&#34;


@fdb.transactional
def write_chunks(tr: fdb.impl.Transaction, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any], addresses: np.ndarray, chunks: List[Union[np.ndarray, MaskedArray]]) -&gt; int:
        &#34;&#34;&#34;
        Write a list of chunks to the database, optionally using mask to write only partially

        Args:
                tr: Transaction object
                subspace: The fdb DirectorySubspace under which the chunks are stored
                key_prefix: The tuple to use as prefix when storing the chunks
                addresses: An (n_chunks, n_dim) numpy array giving the addresses of the desired chunks, along each dimension
                chunks: List of chunks, each of which can optionally be a numpy masked array

        Returns:
                The number of bytes written
        
        Remarks:
                Chunks can be given as numpy masked arrays, and masked values will be filled by the corresponding values from 
                the current chunk at the same address (which must exist). This can be used to selectively update
                only parts of chunks, e.g. when updating part of a tensor or appending values that are nonaligned with chunk edges.
        &#34;&#34;&#34;
        # logging.info(f&#34;Writing {addresses.shape[0]} chunks starting at {addresses[0]}&#34;)
        n_bytes_written = 0
        if len(addresses) == 0:  # writing a scalar
                key = subspace.pack(key_prefix)
                encoded = blosc.pack_array(chunks[0])
                n_bytes_written += len(key) + len(encoded)
                tr[key] = encoded
                return n_bytes_written

        for address, chunk in zip(addresses, chunks):
                key = subspace.pack(key_prefix + tuple(int(x) for x in address))
                if isinstance(chunk, np.ma.MaskedArray):
                        mask = np.ma.getmask(chunk)
                        if np.any(mask):
                                prev_value = read_chunks(tr, subspace, key_prefix, address[None, :])[0]
                                if prev_value is not None:
                                        chunk[mask] = prev_value[mask]
                        chunk = chunk.data
                # chunk is now an ndarray (not masked)
                encoded = blosc.pack_array(chunk)
                n_bytes_written += len(key) + len(encoded)
                tr[key] = encoded
        # logging.info(f&#34;Wrote {addresses.shape[0]} chunks starting at {addresses[0]}, total of {n_bytes_written:,} bytes&#34;)
        return n_bytes_written

@fdb.transactional
def read_chunks(tr: fdb.impl.Transaction, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any], addresses: np.ndarray) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        Read a list of chunks from the database, using a transaction

        Args:
                tr: Transaction object
                subspace: The fdb DirectorySubspace under which the chunks are stored
                key_prefix: The tuple to use as prefix when storing the chunks
                addresses: An (n_chunks, n_dim) numpy array giving the addresses of the desired chunks, along each dimension

        Returns:
                chunks: A list of np.ndarray objects representing the desired chunks
        
        Remarks:
                Chunks that don&#39;t exist in the database are returned as None
        &#34;&#34;&#34;
        # logging.info(f&#34;Reading {addresses.shape[0]} chunks starting at {addresses[0]}&#34;)
        n_bytes_read = 0

        if len(addresses) == 0:  # writing a scalar
                key = subspace.pack(key_prefix)
                data = tr[key].value
                decoded = blosc.unpack_array(data)
                n_bytes_read += len(key) + len(data)
                return [decoded]

        chunks: List[np.ndarray] = []
        for address in addresses:
                key = subspace.pack(key_prefix + tuple(int(x) for x in address))
                data = tr[key].value
                if data is None:
                        chunks.append(None)
                else:
                        decoded = blosc.unpack_array(data)
                        n_bytes_read += len(key) + len(data)
                        chunks.append(decoded)
        # logging.info(f&#34;Read {addresses.shape[0]} chunks starting at {addresses[0]}, total of {n_bytes_read:,} bytes&#34;)
        return chunks

# Note: no @fdb.transactional decorator since this uses multiple transanctions inside the function
def read_chunks_multibatch(db: fdb.impl.Database, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any, ...], addresses: np.ndarray) -&gt; List[np.ndarray]:
        n = len(addresses) # Start by attempting to read everything
        n_total = n
        ix = 0
        chunks = []
        while ix &lt; n_total:
                try:
                        chunks += read_chunks(db, subspace, key_prefix, addresses[ix: ix + n])
                except fdb.impl.FDBError as e:
                        if e.code in (1004, 1007, 1031, 2101) and n &gt; 1:  # Too many bytes or too long time, so try again with less
                                n = max(1, n // 2)
                                continue
                        else:
                                raise e
                ix += n
        return chunks</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="shoji.io.chunked_io.read_chunks"><code class="name flex">
<span>def <span class="ident">read_chunks</span></span>(<span>tr: fdb.impl.Transaction, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any], addresses: numpy.ndarray) ‑> List[numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Read a list of chunks from the database, using a transaction</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tr</code></strong></dt>
<dd>Transaction object</dd>
<dt><strong><code>subspace</code></strong></dt>
<dd>The fdb DirectorySubspace under which the chunks are stored</dd>
<dt><strong><code>key_prefix</code></strong></dt>
<dd>The tuple to use as prefix when storing the chunks</dd>
<dt><strong><code>addresses</code></strong></dt>
<dd>An (n_chunks, n_dim) numpy array giving the addresses of the desired chunks, along each dimension</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>chunks</code></dt>
<dd>A list of np.ndarray objects representing the desired chunks</dd>
</dl>
<h2 id="remarks">Remarks</h2>
<p>Chunks that don't exist in the database are returned as None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@fdb.transactional
def read_chunks(tr: fdb.impl.Transaction, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any], addresses: np.ndarray) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        Read a list of chunks from the database, using a transaction

        Args:
                tr: Transaction object
                subspace: The fdb DirectorySubspace under which the chunks are stored
                key_prefix: The tuple to use as prefix when storing the chunks
                addresses: An (n_chunks, n_dim) numpy array giving the addresses of the desired chunks, along each dimension

        Returns:
                chunks: A list of np.ndarray objects representing the desired chunks
        
        Remarks:
                Chunks that don&#39;t exist in the database are returned as None
        &#34;&#34;&#34;
        # logging.info(f&#34;Reading {addresses.shape[0]} chunks starting at {addresses[0]}&#34;)
        n_bytes_read = 0

        if len(addresses) == 0:  # writing a scalar
                key = subspace.pack(key_prefix)
                data = tr[key].value
                decoded = blosc.unpack_array(data)
                n_bytes_read += len(key) + len(data)
                return [decoded]

        chunks: List[np.ndarray] = []
        for address in addresses:
                key = subspace.pack(key_prefix + tuple(int(x) for x in address))
                data = tr[key].value
                if data is None:
                        chunks.append(None)
                else:
                        decoded = blosc.unpack_array(data)
                        n_bytes_read += len(key) + len(data)
                        chunks.append(decoded)
        # logging.info(f&#34;Read {addresses.shape[0]} chunks starting at {addresses[0]}, total of {n_bytes_read:,} bytes&#34;)
        return chunks</code></pre>
</details>
</dd>
<dt id="shoji.io.chunked_io.read_chunks_multibatch"><code class="name flex">
<span>def <span class="ident">read_chunks_multibatch</span></span>(<span>db: fdb.impl.Database, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any, ...], addresses: numpy.ndarray) ‑> List[numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_chunks_multibatch(db: fdb.impl.Database, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any, ...], addresses: np.ndarray) -&gt; List[np.ndarray]:
        n = len(addresses) # Start by attempting to read everything
        n_total = n
        ix = 0
        chunks = []
        while ix &lt; n_total:
                try:
                        chunks += read_chunks(db, subspace, key_prefix, addresses[ix: ix + n])
                except fdb.impl.FDBError as e:
                        if e.code in (1004, 1007, 1031, 2101) and n &gt; 1:  # Too many bytes or too long time, so try again with less
                                n = max(1, n // 2)
                                continue
                        else:
                                raise e
                ix += n
        return chunks</code></pre>
</details>
</dd>
<dt id="shoji.io.chunked_io.write_chunks"><code class="name flex">
<span>def <span class="ident">write_chunks</span></span>(<span>tr: fdb.impl.Transaction, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any], addresses: numpy.ndarray, chunks: List[Union[numpy.ndarray, numpy.ma.core.MaskedArray]]) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>Write a list of chunks to the database, optionally using mask to write only partially</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tr</code></strong></dt>
<dd>Transaction object</dd>
<dt><strong><code>subspace</code></strong></dt>
<dd>The fdb DirectorySubspace under which the chunks are stored</dd>
<dt><strong><code>key_prefix</code></strong></dt>
<dd>The tuple to use as prefix when storing the chunks</dd>
<dt><strong><code>addresses</code></strong></dt>
<dd>An (n_chunks, n_dim) numpy array giving the addresses of the desired chunks, along each dimension</dd>
<dt><strong><code>chunks</code></strong></dt>
<dd>List of chunks, each of which can optionally be a numpy masked array</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The number of bytes written</p>
<h2 id="remarks">Remarks</h2>
<p>Chunks can be given as numpy masked arrays, and masked values will be filled by the corresponding values from
the current chunk at the same address (which must exist). This can be used to selectively update
only parts of chunks, e.g. when updating part of a tensor or appending values that are nonaligned with chunk edges.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@fdb.transactional
def write_chunks(tr: fdb.impl.Transaction, subspace: fdb.directory_impl.DirectorySubspace, key_prefix: Tuple[Any], addresses: np.ndarray, chunks: List[Union[np.ndarray, MaskedArray]]) -&gt; int:
        &#34;&#34;&#34;
        Write a list of chunks to the database, optionally using mask to write only partially

        Args:
                tr: Transaction object
                subspace: The fdb DirectorySubspace under which the chunks are stored
                key_prefix: The tuple to use as prefix when storing the chunks
                addresses: An (n_chunks, n_dim) numpy array giving the addresses of the desired chunks, along each dimension
                chunks: List of chunks, each of which can optionally be a numpy masked array

        Returns:
                The number of bytes written
        
        Remarks:
                Chunks can be given as numpy masked arrays, and masked values will be filled by the corresponding values from 
                the current chunk at the same address (which must exist). This can be used to selectively update
                only parts of chunks, e.g. when updating part of a tensor or appending values that are nonaligned with chunk edges.
        &#34;&#34;&#34;
        # logging.info(f&#34;Writing {addresses.shape[0]} chunks starting at {addresses[0]}&#34;)
        n_bytes_written = 0
        if len(addresses) == 0:  # writing a scalar
                key = subspace.pack(key_prefix)
                encoded = blosc.pack_array(chunks[0])
                n_bytes_written += len(key) + len(encoded)
                tr[key] = encoded
                return n_bytes_written

        for address, chunk in zip(addresses, chunks):
                key = subspace.pack(key_prefix + tuple(int(x) for x in address))
                if isinstance(chunk, np.ma.MaskedArray):
                        mask = np.ma.getmask(chunk)
                        if np.any(mask):
                                prev_value = read_chunks(tr, subspace, key_prefix, address[None, :])[0]
                                if prev_value is not None:
                                        chunk[mask] = prev_value[mask]
                        chunk = chunk.data
                # chunk is now an ndarray (not masked)
                encoded = blosc.pack_array(chunk)
                n_bytes_written += len(key) + len(encoded)
                tr[key] = encoded
        # logging.info(f&#34;Wrote {addresses.shape[0]} chunks starting at {addresses[0]}, total of {n_bytes_written:,} bytes&#34;)
        return n_bytes_written</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="shoji.io" href="index.html">shoji.io</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="shoji.io.chunked_io.read_chunks" href="#shoji.io.chunked_io.read_chunks">read_chunks</a></code></li>
<li><code><a title="shoji.io.chunked_io.read_chunks_multibatch" href="#shoji.io.chunked_io.read_chunks_multibatch">read_chunks_multibatch</a></code></li>
<li><code><a title="shoji.io.chunked_io.write_chunks" href="#shoji.io.chunked_io.write_chunks">write_chunks</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>