<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>shoji.tensor API documentation</title>
<meta name="description" content="All data in Shoji is stored as N-dimensional tensors. A tensor is a
generalisation of scalars, vectors and matrices to N dimensions …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>shoji.tensor</code></h1>
</header>
<section id="section-intro">
<p>All data in Shoji is stored as N-dimensional tensors. A tensor is a
generalisation of scalars, vectors and matrices to N dimensions. </p>
<p>The atomic unit of storage is the <em>row</em>. Tensors are read and written by row,
and tensors can grow (only) by rows.</p>
<h2 id="overview">Overview</h2>
<p>Tensors are defined by their <em>rank</em>, <em>datatype</em>, <em>dimensions</em> and <em>shape</em>.</p>
<p><img alt="" src="assets/bitmap/tensor_rank@2x.png"></p>
<p>Tensors are created like this:</p>
<pre><code class="python">import shoji
tissues = ...        # Assume we have an np.ndarray of tissue names
db = shoji.connect() # Connect to the database
ws = db.scRNA        # scRNA is a Workspace in the database, previously created

ws.Tissue = shoji.Tensor(&quot;string&quot;, (&quot;cells&quot;,), tissues)
</code></pre>
<p>The tensor is declared with a datatype <code>"string"</code>, a tuple of dimensions <code>("cells",)</code> and an optional <code>np.ndarray</code> of initial values.</p>
<h3 id="rank">Rank</h3>
<p>The <em>rank</em> of a tensor is the number of dimensions of the tensor. A scalar
value has rank 0, a vector has rank 1, and a matrix has rank 2. Higher ranks
are possible; for example, a vector of 2D images would have rank 3, and a
timelapse recording in three color channels would have rank 6 (time, width, height,
three colors).</p>
<h3 id="datatype">Datatype</h3>
<p>Tensors support the following datatypes: </p>
<pre><code class="python">&quot;bool&quot;
&quot;uint8&quot;, &quot;uint16&quot;, &quot;uint32&quot;, &quot;uint64&quot;
&quot;int8&quot;, &quot;int16&quot;, &quot;int32&quot;, &quot;int64&quot;
&quot;float16&quot;, &quot;float32&quot;, &quot;float64&quot;
&quot;string&quot;
</code></pre>
<p>The datatype of a tensor must always be declared; there is no default type.</p>
<p>When a tensor is created, any initial values provided (via the <code>inits</code> argument) must have the matching numpy datatype. The bool and numeric datatypes match 1:1 with numpy dtypes. </p>
<p>However, the Shoji <code>string</code> datatype is a Unicode string of variable length, which corresponds to a numpy array of string objects. That is, the corresponding numpy datatype is <em>not</em> <code>str</code> or <code>"unicode"</code>. Instead, Shoji string tensors correspond to numpy <code>object</code> arrays whose elements are Python <code>str</code> objects. You can cast a numpy <code>str</code> array to an <code>object</code> array as follows:</p>
<pre><code class="python">import numpy as np
s = np.array([&quot;dog&quot;, &quot;cat&quot;, &quot;apple&quot;, &quot;orange&quot;])  # s.dtype.kind == 'U'
t = s.astype(object)  # t.dtype.kind == 'O'
# Or directly, using dtype
s = np.array([&quot;dog&quot;, &quot;cat&quot;, &quot;apple&quot;, &quot;orange&quot;], dtype=&quot;object&quot;)
</code></pre>
<p>The reason for this discrepancy is that numpy <code>str</code> arrays store only fixed-length strings, whereas Shoji <code>string</code> tensors store strings of variable length.</p>
<h3 id="dimensions">Dimensions</h3>
<p>When creating a tensor, its dimensions must be declared using a tuple.
Scalars have rank zero, and are declared with the empty tuple <code>()</code>.
Vectors have rank one, and are declared with a single-element tuple, e.g.
<code>(20,)</code> (note the comma, which is necessary). Matrices have rank 2, and are
declared with a two-element tuple, e.g. <code>(20, 40)</code>. Higher-rank tensors are
declared with correspondingly longer tuples. </p>
<p>Dimensions can be fixed or variable-length. A fixed-length dimension is
declared with an integer specifying the number of elements of the dimension.
A variable-length dimension is declared as <code>None</code>. For example, <code>(10, None)</code>
is a matrix with ten rows and a variable number of columns (also known as a
jagged array).</p>
<p>The meaning of a variable-length first dimension is slightly different. The
first dimension cannot be jagged, but if it's declared variable-length then
the tensor can grow over time. Thus a tensor declared with
<code>dims=(None, 10)</code> is not jagged (at any point in time it has a fixed number of
rows and columns), but rows can be appended (see <code><a title="shoji.dimension" href="dimension.html">shoji.dimension</a></code> and <code><a title="shoji.dimension.Dimension.append" href="dimension.html#shoji.dimension.Dimension.append">Dimension.append()</a></code>).</p>
<p>Each dimension of a tensor can be named, and named dimensions (within a
<code><a title="shoji.workspace.Workspace" href="workspace.html#shoji.workspace.Workspace">Workspace</a></code>) are constrained to have the same number of elements.
For example, if two tensors are declared with dimensions <code>("cells",)</code>
and <code>("cells", "genes")</code>, then the first dimensions are guaranteed to have
the same number of elements, which are assumed to be in the same order.</p>
<p>Named dimensions must be declared before they are used; see <code><a title="shoji.dimension" href="dimension.html">shoji.dimension</a></code>.</p>
<h3 id="shape">Shape</h3>
<p>The <code>shape</code> of a <code><a title="shoji.tensor.Tensor" href="#shoji.tensor.Tensor">Tensor</a></code> is a tuple of integers that gives the current
shape of the tensor as stored in the database. For example, a tensor with <code>dims=(None, 10, 20)</code>
might have <code>shape=(10, 10, 20)</code>, indicating that currently the tensor has ten rows. Since
the first dimension is variable-length (in this case), rows might be appended later, and the shape
would change to reflect the new number of rows.</p>
<h2 id="key-concept-rows">Key concept: rows</h2>
<p>The <em>row</em> is the atomic unit of data storage in Shoji. For an N-dimensional tensor, the rows are
the slices of the tensor along the first dimension:</p>
<ul>
<li>For a scalar, the single row is the entire scalar.</li>
<li>For a vector, the rows are the elements of the vector.</li>
<li>For a matrix, the rows are the rows of the matrix.</li>
<li>For a 3D tensor, the rows are the matrices along the first dimension, and so on for higher-rank tensors.</li>
</ul>
<p>Data in Shoji is stored and retrieved as individual rows. In other words,
you can retrieve selected elements of a vector, or selected rows of a matrix,
but you cannot retrieve the individual columns of a matrix. </p>
<p>You should think of the rows of a tensor as your <em>objects</em>, and each tensor
as an attribute of the objects. Multiple attributes (tensors) are linked
by sharing named dimensions. For example, to store a gene expression matrix
along with two metadata attributes, make <code>"cells"</code> the first dimension (so
that you can add cells), and create two tensors:</p>
<pre><code class="python">ws.cells = shoji.Dimension(shape=None)  # None means variable length
ws.genes = shoji.Dimension(shape=32125)
ws.Expression = shoji.Tensor(&quot;unit16&quot;, (&quot;cells&quot;, &quot;genes&quot;))
ws.Tissue = shoji.Tensor(&quot;string&quot;, (&quot;cells&quot;,))
ws.Age = shoji.Tensor(&quot;uint16&quot;, (&quot;cells&quot;,))
</code></pre>
<p>The three tensors <code>Expression</code>, <code>Tissue</code> and
<code>Age</code> share their first
dimension <code>cells</code>, which ensures that they will always have the same number
of rows (and are assumed to be in the same order).</p>
<p>If the size of the first dimension is variable (declared as <code>None</code>),
then rows can be added and removed. However, shoji makes sure that the same
number of rows is added to all tensors with the same first dimension, so that
they remain consistent with each other. When two or more tensors share the first
dimension (and it's declared variable-length), then you can only append rows
simultaneously to all those tensors (using <code><a title="shoji.dimension.Dimension.append" href="dimension.html#shoji.dimension.Dimension.append">Dimension.append()</a></code>). </p>
<h2 id="jagged-tensors">Jagged tensors</h2>
<p>If any non-first dimension is declared with variable size, then the tensor is
<em>jagged</em>. This means that the size along those dimensions can be different for
different rows. For example:</p>
<pre><code class="python">ws.cells = shoji.Dimension(shape=None)
ws.Image = shoji.Tensor(&quot;uint16&quot;, (&quot;cells&quot;, None, None))
</code></pre>
<p>In this example, we declare a 3D jagged tensor <code>Image</code>, where dimensions 2 and 3
are variable-length. This could be used to store 2D images of cells, each of which
has a different width and height. The first dimension represents the objects
(individual cells) and the 2nd and 3rd dimensions represent the images. Accessing
a single row of this tensor would return a single 2D image matrix. Accessing a set
of rows would return a list of 2D images.</p>
<p>In a similar way, we could store multichannel timelapse images of cells:</p>
<pre><code class="python">ws.cells = shoji.Dimension(shape=None)
ws.channels = shoji.Dimension(shape=3)
ws.timepoints = shoji.Dimension(shape=1200)  # 1200 timepoints
ws.Image = shoji.Tensor(&quot;uint16&quot;, (&quot;cells&quot;, &quot;channels&quot;, &quot;timepoints&quot;, None, None))
</code></pre>
<p>In this examples, <code>Image</code> is a 5-dimensional tensor, where the last two dimensions
have variable length.</p>
<p>Note again that tensors are read and written by row (elements of the first dimension). </p>
<p>There is a 5 second limit on the maximum duration of a read or write, which implicitly
limits the total size of the row of a tensor. If all the data for a single row cannot
be retrieved in less than five seconds, you will have to redesign the data model (e.g.
breaking out some dimensions to a separate tensor).</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
All data in Shoji is stored as N-dimensional tensors. A tensor is a
generalisation of scalars, vectors and matrices to N dimensions. 

The atomic unit of storage is the *row*. Tensors are read and written by row,
and tensors can grow (only) by rows.

## Overview

Tensors are defined by their *rank*, *datatype*, *dimensions* and *shape*.

..image:: assets/bitmap/tensor_rank@2x.png

Tensors are created like this:

```python
import shoji
tissues = ...        # Assume we have an np.ndarray of tissue names
db = shoji.connect() # Connect to the database
ws = db.scRNA        # scRNA is a Workspace in the database, previously created

ws.Tissue = shoji.Tensor(&#34;string&#34;, (&#34;cells&#34;,), tissues)
```

The tensor is declared with a datatype `&#34;string&#34;`, a tuple of dimensions `(&#34;cells&#34;,)` and an optional `np.ndarray` of initial values.

### Rank

The *rank* of a tensor is the number of dimensions of the tensor. A scalar 
value has rank 0, a vector has rank 1, and a matrix has rank 2. Higher ranks
are possible; for example, a vector of 2D images would have rank 3, and a
timelapse recording in three color channels would have rank 6 (time, width, height,
three colors).

### Datatype

Tensors support the following datatypes: 

```python
&#34;bool&#34;
&#34;uint8&#34;, &#34;uint16&#34;, &#34;uint32&#34;, &#34;uint64&#34;
&#34;int8&#34;, &#34;int16&#34;, &#34;int32&#34;, &#34;int64&#34;
&#34;float16&#34;, &#34;float32&#34;, &#34;float64&#34;
&#34;string&#34;
```

The datatype of a tensor must always be declared; there is no default type.

When a tensor is created, any initial values provided (via the `inits` argument) must have the matching numpy datatype. The bool and numeric datatypes match 1:1 with numpy dtypes. 

However, the Shoji `string` datatype is a Unicode string of variable length, which corresponds to a numpy array of string objects. That is, the corresponding numpy datatype is *not* `str` or `&#34;unicode&#34;`. Instead, Shoji string tensors correspond to numpy `object` arrays whose elements are Python `str` objects. You can cast a numpy `str` array to an `object` array as follows:

```python
import numpy as np
s = np.array([&#34;dog&#34;, &#34;cat&#34;, &#34;apple&#34;, &#34;orange&#34;])  # s.dtype.kind == &#39;U&#39;
t = s.astype(object)  # t.dtype.kind == &#39;O&#39;
# Or directly, using dtype
s = np.array([&#34;dog&#34;, &#34;cat&#34;, &#34;apple&#34;, &#34;orange&#34;], dtype=&#34;object&#34;)
```

The reason for this discrepancy is that numpy `str` arrays store only fixed-length strings, whereas Shoji `string` tensors store strings of variable length.

### Dimensions

When creating a tensor, its dimensions must be declared using a tuple. 
Scalars have rank zero, and are declared with the empty tuple `()`. 
Vectors have rank one, and are declared with a single-element tuple, e.g. 
`(20,)` (note the comma, which is necessary). Matrices have rank 2, and are
declared with a two-element tuple, e.g. `(20, 40)`. Higher-rank tensors are 
declared with correspondingly longer tuples. 

Dimensions can be fixed or variable-length. A fixed-length dimension is 
declared with an integer specifying the number of elements of the dimension.
A variable-length dimension is declared as `None`. For example, `(10, None)` 
is a matrix with ten rows and a variable number of columns (also known as a
jagged array).

The meaning of a variable-length first dimension is slightly different. The
first dimension cannot be jagged, but if it&#39;s declared variable-length then 
the tensor can grow over time. Thus a tensor declared with 
`dims=(None, 10)` is not jagged (at any point in time it has a fixed number of
rows and columns), but rows can be appended (see `shoji.dimension` and `shoji.dimension.Dimension.append`).

Each dimension of a tensor can be named, and named dimensions (within a 
`shoji.workspace.Workspace`) are constrained to have the same number of elements. 
For example, if two tensors are declared with dimensions `(&#34;cells&#34;,)` 
and `(&#34;cells&#34;, &#34;genes&#34;)`, then the first dimensions are guaranteed to have 
the same number of elements, which are assumed to be in the same order.

Named dimensions must be declared before they are used; see `shoji.dimension`.


### Shape

The `shape` of a `shoji.tensor.Tensor` is a tuple of integers that gives the current
shape of the tensor as stored in the database. For example, a tensor with `dims=(None, 10, 20)`
might have `shape=(10, 10, 20)`, indicating that currently the tensor has ten rows. Since
the first dimension is variable-length (in this case), rows might be appended later, and the shape
would change to reflect the new number of rows.


## Key concept: rows

The *row* is the atomic unit of data storage in Shoji. For an N-dimensional tensor, the rows are 
the slices of the tensor along the first dimension:

- For a scalar, the single row is the entire scalar.
- For a vector, the rows are the elements of the vector.
- For a matrix, the rows are the rows of the matrix.
- For a 3D tensor, the rows are the matrices along the first dimension, and so on for higher-rank tensors.

Data in Shoji is stored and retrieved as individual rows. In other words, 
you can retrieve selected elements of a vector, or selected rows of a matrix, 
but you cannot retrieve the individual columns of a matrix. 

You should think of the rows of a tensor as your *objects*, and each tensor 
as an attribute of the objects. Multiple attributes (tensors) are linked 
by sharing named dimensions. For example, to store a gene expression matrix 
along with two metadata attributes, make `&#34;cells&#34;` the first dimension (so 
that you can add cells), and create two tensors:

```python
ws.cells = shoji.Dimension(shape=None)  # None means variable length
ws.genes = shoji.Dimension(shape=32125)
ws.Expression = shoji.Tensor(&#34;unit16&#34;, (&#34;cells&#34;, &#34;genes&#34;))
ws.Tissue = shoji.Tensor(&#34;string&#34;, (&#34;cells&#34;,))
ws.Age = shoji.Tensor(&#34;uint16&#34;, (&#34;cells&#34;,))
```

The three tensors `Expression`, `Tissue` and  `Age` share their first 
dimension `cells`, which ensures that they will always have the same number 
of rows (and are assumed to be in the same order).

If the size of the first dimension is variable (declared as `None`), 
then rows can be added and removed. However, shoji makes sure that the same
number of rows is added to all tensors with the same first dimension, so that
they remain consistent with each other. When two or more tensors share the first
dimension (and it&#39;s declared variable-length), then you can only append rows
simultaneously to all those tensors (using `shoji.dimension.Dimension.append`). 


## Jagged tensors

If any non-first dimension is declared with variable size, then the tensor is 
*jagged*. This means that the size along those dimensions can be different for 
different rows. For example:

```python
ws.cells = shoji.Dimension(shape=None)
ws.Image = shoji.Tensor(&#34;uint16&#34;, (&#34;cells&#34;, None, None))
```

In this example, we declare a 3D jagged tensor `Image`, where dimensions 2 and 3 
are variable-length. This could be used to store 2D images of cells, each of which 
has a different width and height. The first dimension represents the objects 
(individual cells) and the 2nd and 3rd dimensions represent the images. Accessing 
a single row of this tensor would return a single 2D image matrix. Accessing a set 
of rows would return a list of 2D images.

In a similar way, we could store multichannel timelapse images of cells:

```python
ws.cells = shoji.Dimension(shape=None)
ws.channels = shoji.Dimension(shape=3)
ws.timepoints = shoji.Dimension(shape=1200)  # 1200 timepoints
ws.Image = shoji.Tensor(&#34;uint16&#34;, (&#34;cells&#34;, &#34;channels&#34;, &#34;timepoints&#34;, None, None))
```

In this examples, `Image` is a 5-dimensional tensor, where the last two dimensions 
have variable length.

Note again that tensors are read and written by row (elements of the first dimension). 

There is a 5 second limit on the maximum duration of a read or write, which implicitly 
limits the total size of the row of a tensor. If all the data for a single row cannot 
be retrieved in less than five seconds, you will have to redesign the data model (e.g. 
breaking out some dimensions to a separate tensor).
&#34;&#34;&#34;
from typing import Tuple, Union, List, Optional, Callable
import numpy as np
import shoji


class TensorValue:
        def __init__(self, values: Union[Tuple[np.ndarray], List[np.ndarray], np.ndarray]) -&gt; None:
                self.values = values

                if isinstance(values, (list, tuple)):
                        self.jagged = True
                        self.rank = values[0].ndim + 1
                        self.dtype = values[0].dtype.name
                        if self.dtype == &#34;object&#34;:
                                self.dtype = &#34;string&#34;

                        shape: List[int] = list(values[0].shape)
                        for i, array in enumerate(values):
                                if not isinstance(array, np.ndarray):
                                        raise ValueError(&#34;Rows of jagged tensor must be numpy ndarrays&#34;)
                                if self.rank != array.ndim + 1:
                                        raise ValueError(&#34;Rows of jagged tensor cannot be mixed rank&#34;)
                                if self.dtype != array.dtype:
                                        raise ValueError(&#34;Rows of jagged tensor cannot be mixed dtype&#34;)
                                if self.dtype == &#34;string&#34;:
                                        if not all([isinstance(x, str) for x in array.flat]):
                                                raise TypeError(&#34;string tensors (numpy dtype=&#39;object&#39;) must contain only string elements&#34;)
                                if array.ndim != len(shape):
                                        raise ValueError(f&#34;Rank mismatch: shape {array.shape} of subarray at row {i} is not the same rank as shape {shape} at row 0&#34;)
                                for ix in range(len(shape)):
                                        if shape[ix] != array.shape[ix]:
                                                shape[ix] = 0
                        self.shape = tuple([len(values)] + shape)                       
                else:
                        self.jagged = False
                        self.rank = values.ndim
                        self.dtype = values.dtype.name
                        if self.dtype == &#34;object&#34;:
                                self.dtype = &#34;string&#34;
                                if not all([isinstance(x, str) for x in values.flat]):
                                        raise TypeError(&#34;string tensors (numpy dtype=&#39;object&#39;) must contain only string elements&#34;)
                        self.shape = values.shape

                if self.dtype not in Tensor.valid_types:
                        raise TypeError(f&#34;Invalid dtype &#39;{self.dtype}&#39; for tensor value&#34;)


        @property
        def size(self) -&gt; int:
                return np.prod(self.shape)

        def __len__(self) -&gt; int:
                if self.rank &gt; 0:
                        return self.shape[0]
                return 1
        
        def __iter__(self):
                for row in self.values:
                        yield row

        def size_in_bytes(self) -&gt; int:
                n_bytes = 0
                if not self.jagged:
                        if self.dtype == &#34;string&#34;:
                                n_bytes += sum([len(s) for s in self.values]) * 2
                        else:
                                n_bytes += self.values.size * self.values.itemsize  # type: ignore
                else:
                        for row in self.values:
                                if self.dtype == &#34;string&#34;:
                                        n_bytes += sum([len(s) for s in row]) * 2
                                else:
                                        n_bytes += row.size * row.itemsize
                return n_bytes

class Tensor:
        valid_types = (&#34;bool&#34;, &#34;uint8&#34;, &#34;uint16&#34;, &#34;uint32&#34;, &#34;uint64&#34;, &#34;int8&#34;, &#34;int16&#34;, &#34;int32&#34;, &#34;int64&#34;, &#34;float16&#34;, &#34;float32&#34;, &#34;float64&#34;, &#34;string&#34;)

        def __init__(self, dtype: str, dims: Union[Tuple[Union[None, int, str], ...]], inits: Union[List[np.ndarray], np.ndarray] = None, shape: Tuple[int, ...] = None) -&gt; None:
                &#34;&#34;&#34;
                Args:
                        dtype:  string giving the datatype of the tensor elements
                        dims:   A tuple of None, int, string (empty tuple designates a scalar)
                        inits:  Optional values to initialize the tensor with

                Remarks:
                        Dimensions are specified as:

                                None:           resizable/jagged anonymous dimension
                                int:            fixed-shape anonymous dimension
                                string:         named dimension
                        
                        The first dimension can be fixed-shape or resizable; all other dimensions can be fixed-shape or jagged. 
                &#34;&#34;&#34;
                self.dtype = dtype
                # Check that the type is valid
                if dtype not in Tensor.valid_types:
                        raise TypeError(f&#34;Invalid Tensor type {dtype}&#34;)

                self.dims = dims
        
                self.name = &#34;&#34;  # Will be set if the Tensor is read from the db
                self.wsm: Optional[shoji.WorkspaceManager] = None  # Will be set if the Tensor is read from the db

                if inits is None:
                        self.inits: TensorValue = None
                        self.jagged = False
                        self.shape = shape if shape is not None else (0,) * len(dims)
                else:
                        # If scalar, convert to an ndarray scalar which will have shape ()
                        if np.isscalar(inits):
                                self.inits = TensorValue(np.array(inits, dtype=self.numpy_dtype()))
                        else:
                                self.inits = TensorValue(inits)
                        self.jagged = self.inits.jagged
                        self.shape = self.inits.shape

                        if len(self.dims) != len(self.shape):
                                raise ValueError(f&#34;Rank mismatch: shape {self.dims} declared is not the same rank as shape {self.shape} of values&#34;)

                        if self.dtype != self.inits.dtype:
                                raise TypeError(f&#34;Tensor dtype &#39;{self.dtype}&#39; does not match dtype of inits &#39;{self.inits.dtype}&#39;&#34;)

                for ix, dim in enumerate(self.dims):
                        if dim is not None and not isinstance(dim, int) and not isinstance(dim, str):
                                raise ValueError(f&#34;Dimension {ix} &#39;{dim}&#39; is invalid (must be None, int or str)&#34;)

                        if isinstance(dim, int) and self.inits is not None:
                                if self.shape[ix] != dim:  # type: ignore
                                        raise IndexError(f&#34;Mismatch between the declared shape {dim} of dimension {ix} and the inferred shape {self.shape} of values&#34;)

                self.rank = len(self.dims)

        def __len__(self) -&gt; int:
                if self.rank &gt; 0:
                        return self.shape[0]
                return 0

        def __getitem__(self, expr: Union[&#34;shoji.Filter&#34;, tuple, slice, int]) -&gt; np.ndarray:
                assert self.wsm is not None, &#34;Tensor is not bound to a database&#34;
                # Maybe it&#39;s a Filter?
                if isinstance(expr, shoji.Filter):
                        return shoji.View(self.wsm, (expr,))[self.name]
                # Or a slice?
                if isinstance(expr, slice):
                        if expr.start is None and expr.stop is None:
                                return shoji.View(self.wsm, ())[self.name]
                        return shoji.View(self.wsm, (shoji.TensorSliceFilter(self, expr),))[self.name]
                if isinstance(expr, (list, tuple, int)):
                        expr = np.array(expr)
                if isinstance(expr, np.ndarray):
                        if np.issubdtype(expr.dtype, np.bool_):
                                return shoji.View(self.wsm, (shoji.TensorBoolFilter(self, expr),))[self.name]
                        elif np.issubdtype(expr.dtype, np.int_):
                                return shoji.View(self.wsm, (shoji.TensorIndicesFilter(self, expr),))[self.name]
                raise KeyError(expr)

        def __setitem__(self, expr: Union[&#34;shoji.Filter&#34;, tuple, slice, int], vals: np.ndarray) -&gt; None:
                assert self.wsm is not None, &#34;Tensor is not bound to a database&#34;
                # Maybe it&#39;s a Filter?
                if isinstance(expr, shoji.Filter):
                        shoji.View(self.wsm, (expr,))[self.name] = vals
                # Or a slice?
                if isinstance(expr, slice):
                        if expr.start is None and expr.stop is None:
                                shoji.View(self.wsm, ())[self.name] = vals
                        shoji.View(self.wsm, (shoji.TensorSliceFilter(self, expr),))[self.name] = vals
                if isinstance(expr, (list, tuple, int)):
                        expr = np.array(expr)
                if isinstance(expr, np.ndarray):
                        if np.issubdtype(expr.dtype, np.bool_):
                                shoji.View(self.wsm, (shoji.TensorBoolFilter(self, expr),))[self.name] = vals
                        elif np.issubdtype(expr.dtype, np.int_):
                                shoji.View(self.wsm, (shoji.TensorIndicesFilter(self, expr),))[self.name] = vals
                raise KeyError(expr)

        def numpy_dtype(self) -&gt; str:
                if self.dtype == &#34;string&#34;:
                        return &#34;object&#34;
                return self.dtype

        def python_dtype(self) -&gt; Callable:
                if self.dtype == &#34;string&#34;:
                        return str
                if self.dtype == &#34;bool&#34;:
                        return bool
                if self.dtype in (&#34;float16&#34;, &#34;float32&#34;, &#34;float64&#34;):
                        return float
                return int

        def _compare(self, operator, other) -&gt; &#34;shoji.Filter&#34;:
                if isinstance(other, Tensor):
                        return shoji.TensorFilter(operator, self, other)
                elif isinstance(other, str) or isinstance(other, int) or isinstance(other, float) or isinstance(other, bool):
                        return shoji.ConstFilter(operator, self, other)
                else:
                        raise TypeError(&#34;Invalid operands for expression&#34;)

        def __eq__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;==&#34;, other)
                
        def __ne__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;!=&#34;, other)

        def __gt__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&gt;&#34;, other)

        def __lt__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&lt;&#34;, other)

        def __ge__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&gt;=&#34;, other)

        def __le__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&lt;=&#34;, other)

        def append(self, vals: Union[List[np.ndarray], np.ndarray]) -&gt; None:
                assert self.wsm is not None, &#34;Cannot append to unbound tensor&#34;
                
                if self.rank == 0:
                        raise ValueError(&#34;Cannot append to a scalar&#34;)
                if isinstance(self.dims[0], str):
                        if self.wsm is not None:
                                d = self.wsm[self.dims[0]]
                                if isinstance(d, shoji.Dimension):
                                        d.append(vals)
                                        return
                        raise ValueError(f&#34;Failed to append along named first dimension {self.dims[0]}&#34;)

                tv = TensorValue(vals)
                n_bytes = tv.size_in_bytes()
                n_batches = max(1, n_bytes // 5_000_000) # Should be plenty, given that we&#39;ll also be compressing the rows when writing
                n_rows_per_transaction = max(1, len(vals) // n_batches)
                ix: int = 0
                while ix &lt; len(vals):
                        batch = {self.name: vals[ix: ix + n_rows_per_transaction]}
                        shoji.io.append_tensors(self.wsm._db.transaction, self.wsm, self.name, batch)
                        ix += n_rows_per_transaction

        def _quick_look(self) -&gt; str:
                if self.rank == 0:
                        if self.dtype == &#34;string&#34;:
                                s = f&#39;&#34;{self[:]}&#34;&#39;
                        else:
                                s = str(self[:])
                        if len(s) &gt; 60:
                                return s[:56] + &#34; ...&#34;
                        return s

                def look(vals) -&gt; str:
                        s = &#34;[&#34;
                        if not isinstance(vals, list) and vals.ndim == 1:
                                if self.dtype == &#34;string&#34;:
                                        s += &#34;, &#34;.join([f&#39;&#34;{x}&#34;&#39; for x in vals[:5]])
                                else:
                                        s += &#34;, &#34;.join([str(x) for x in vals[:5]])
                        else:
                                elms = []
                                for val in vals[:5]:
                                        elms.append(look(val))
                                s += &#34;, &#34;.join(elms)
                        if len(vals) &gt; 5:
                                s += &#34;, ...]&#34;
                        else:
                                s += &#34;]&#34;
                        return s

                s = look(self[:10])
                if len(s) &gt; 60:
                        return s[:56] + &#34; ···&#34;
                return s



        def __repr__(self) -&gt; str:
                return f&#34;&lt;Tensor {self.name} dtype=&#39;{self.dtype}&#39; dims={self.dims}, shape={self.shape}&gt;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="shoji.tensor.Tensor"><code class="flex name class">
<span>class <span class="ident">Tensor</span></span>
<span>(</span><span>dtype: str, dims: Tuple[Union[NoneType, int, str], ...], inits: Union[List[numpy.ndarray], numpy.ndarray] = None, shape: Tuple[int, ...] = None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>dtype</code></strong></dt>
<dd>string giving the datatype of the tensor elements</dd>
<dt><strong><code>dims</code></strong></dt>
<dd>A tuple of None, int, string (empty tuple designates a scalar)</dd>
<dt><strong><code>inits</code></strong></dt>
<dd>Optional values to initialize the tensor with</dd>
</dl>
<h2 id="remarks">Remarks</h2>
<p>Dimensions are specified as:</p>
<pre><code>    None:           resizable/jagged anonymous dimension
    int:            fixed-shape anonymous dimension
    string:         named dimension
</code></pre>
<p>The first dimension can be fixed-shape or resizable; all other dimensions can be fixed-shape or jagged.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Tensor:
        valid_types = (&#34;bool&#34;, &#34;uint8&#34;, &#34;uint16&#34;, &#34;uint32&#34;, &#34;uint64&#34;, &#34;int8&#34;, &#34;int16&#34;, &#34;int32&#34;, &#34;int64&#34;, &#34;float16&#34;, &#34;float32&#34;, &#34;float64&#34;, &#34;string&#34;)

        def __init__(self, dtype: str, dims: Union[Tuple[Union[None, int, str], ...]], inits: Union[List[np.ndarray], np.ndarray] = None, shape: Tuple[int, ...] = None) -&gt; None:
                &#34;&#34;&#34;
                Args:
                        dtype:  string giving the datatype of the tensor elements
                        dims:   A tuple of None, int, string (empty tuple designates a scalar)
                        inits:  Optional values to initialize the tensor with

                Remarks:
                        Dimensions are specified as:

                                None:           resizable/jagged anonymous dimension
                                int:            fixed-shape anonymous dimension
                                string:         named dimension
                        
                        The first dimension can be fixed-shape or resizable; all other dimensions can be fixed-shape or jagged. 
                &#34;&#34;&#34;
                self.dtype = dtype
                # Check that the type is valid
                if dtype not in Tensor.valid_types:
                        raise TypeError(f&#34;Invalid Tensor type {dtype}&#34;)

                self.dims = dims
        
                self.name = &#34;&#34;  # Will be set if the Tensor is read from the db
                self.wsm: Optional[shoji.WorkspaceManager] = None  # Will be set if the Tensor is read from the db

                if inits is None:
                        self.inits: TensorValue = None
                        self.jagged = False
                        self.shape = shape if shape is not None else (0,) * len(dims)
                else:
                        # If scalar, convert to an ndarray scalar which will have shape ()
                        if np.isscalar(inits):
                                self.inits = TensorValue(np.array(inits, dtype=self.numpy_dtype()))
                        else:
                                self.inits = TensorValue(inits)
                        self.jagged = self.inits.jagged
                        self.shape = self.inits.shape

                        if len(self.dims) != len(self.shape):
                                raise ValueError(f&#34;Rank mismatch: shape {self.dims} declared is not the same rank as shape {self.shape} of values&#34;)

                        if self.dtype != self.inits.dtype:
                                raise TypeError(f&#34;Tensor dtype &#39;{self.dtype}&#39; does not match dtype of inits &#39;{self.inits.dtype}&#39;&#34;)

                for ix, dim in enumerate(self.dims):
                        if dim is not None and not isinstance(dim, int) and not isinstance(dim, str):
                                raise ValueError(f&#34;Dimension {ix} &#39;{dim}&#39; is invalid (must be None, int or str)&#34;)

                        if isinstance(dim, int) and self.inits is not None:
                                if self.shape[ix] != dim:  # type: ignore
                                        raise IndexError(f&#34;Mismatch between the declared shape {dim} of dimension {ix} and the inferred shape {self.shape} of values&#34;)

                self.rank = len(self.dims)

        def __len__(self) -&gt; int:
                if self.rank &gt; 0:
                        return self.shape[0]
                return 0

        def __getitem__(self, expr: Union[&#34;shoji.Filter&#34;, tuple, slice, int]) -&gt; np.ndarray:
                assert self.wsm is not None, &#34;Tensor is not bound to a database&#34;
                # Maybe it&#39;s a Filter?
                if isinstance(expr, shoji.Filter):
                        return shoji.View(self.wsm, (expr,))[self.name]
                # Or a slice?
                if isinstance(expr, slice):
                        if expr.start is None and expr.stop is None:
                                return shoji.View(self.wsm, ())[self.name]
                        return shoji.View(self.wsm, (shoji.TensorSliceFilter(self, expr),))[self.name]
                if isinstance(expr, (list, tuple, int)):
                        expr = np.array(expr)
                if isinstance(expr, np.ndarray):
                        if np.issubdtype(expr.dtype, np.bool_):
                                return shoji.View(self.wsm, (shoji.TensorBoolFilter(self, expr),))[self.name]
                        elif np.issubdtype(expr.dtype, np.int_):
                                return shoji.View(self.wsm, (shoji.TensorIndicesFilter(self, expr),))[self.name]
                raise KeyError(expr)

        def __setitem__(self, expr: Union[&#34;shoji.Filter&#34;, tuple, slice, int], vals: np.ndarray) -&gt; None:
                assert self.wsm is not None, &#34;Tensor is not bound to a database&#34;
                # Maybe it&#39;s a Filter?
                if isinstance(expr, shoji.Filter):
                        shoji.View(self.wsm, (expr,))[self.name] = vals
                # Or a slice?
                if isinstance(expr, slice):
                        if expr.start is None and expr.stop is None:
                                shoji.View(self.wsm, ())[self.name] = vals
                        shoji.View(self.wsm, (shoji.TensorSliceFilter(self, expr),))[self.name] = vals
                if isinstance(expr, (list, tuple, int)):
                        expr = np.array(expr)
                if isinstance(expr, np.ndarray):
                        if np.issubdtype(expr.dtype, np.bool_):
                                shoji.View(self.wsm, (shoji.TensorBoolFilter(self, expr),))[self.name] = vals
                        elif np.issubdtype(expr.dtype, np.int_):
                                shoji.View(self.wsm, (shoji.TensorIndicesFilter(self, expr),))[self.name] = vals
                raise KeyError(expr)

        def numpy_dtype(self) -&gt; str:
                if self.dtype == &#34;string&#34;:
                        return &#34;object&#34;
                return self.dtype

        def python_dtype(self) -&gt; Callable:
                if self.dtype == &#34;string&#34;:
                        return str
                if self.dtype == &#34;bool&#34;:
                        return bool
                if self.dtype in (&#34;float16&#34;, &#34;float32&#34;, &#34;float64&#34;):
                        return float
                return int

        def _compare(self, operator, other) -&gt; &#34;shoji.Filter&#34;:
                if isinstance(other, Tensor):
                        return shoji.TensorFilter(operator, self, other)
                elif isinstance(other, str) or isinstance(other, int) or isinstance(other, float) or isinstance(other, bool):
                        return shoji.ConstFilter(operator, self, other)
                else:
                        raise TypeError(&#34;Invalid operands for expression&#34;)

        def __eq__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;==&#34;, other)
                
        def __ne__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;!=&#34;, other)

        def __gt__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&gt;&#34;, other)

        def __lt__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&lt;&#34;, other)

        def __ge__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&gt;=&#34;, other)

        def __le__(self, other) -&gt; &#34;shoji.Filter&#34;:  # type: ignore
                return self._compare(&#34;&lt;=&#34;, other)

        def append(self, vals: Union[List[np.ndarray], np.ndarray]) -&gt; None:
                assert self.wsm is not None, &#34;Cannot append to unbound tensor&#34;
                
                if self.rank == 0:
                        raise ValueError(&#34;Cannot append to a scalar&#34;)
                if isinstance(self.dims[0], str):
                        if self.wsm is not None:
                                d = self.wsm[self.dims[0]]
                                if isinstance(d, shoji.Dimension):
                                        d.append(vals)
                                        return
                        raise ValueError(f&#34;Failed to append along named first dimension {self.dims[0]}&#34;)

                tv = TensorValue(vals)
                n_bytes = tv.size_in_bytes()
                n_batches = max(1, n_bytes // 5_000_000) # Should be plenty, given that we&#39;ll also be compressing the rows when writing
                n_rows_per_transaction = max(1, len(vals) // n_batches)
                ix: int = 0
                while ix &lt; len(vals):
                        batch = {self.name: vals[ix: ix + n_rows_per_transaction]}
                        shoji.io.append_tensors(self.wsm._db.transaction, self.wsm, self.name, batch)
                        ix += n_rows_per_transaction

        def _quick_look(self) -&gt; str:
                if self.rank == 0:
                        if self.dtype == &#34;string&#34;:
                                s = f&#39;&#34;{self[:]}&#34;&#39;
                        else:
                                s = str(self[:])
                        if len(s) &gt; 60:
                                return s[:56] + &#34; ...&#34;
                        return s

                def look(vals) -&gt; str:
                        s = &#34;[&#34;
                        if not isinstance(vals, list) and vals.ndim == 1:
                                if self.dtype == &#34;string&#34;:
                                        s += &#34;, &#34;.join([f&#39;&#34;{x}&#34;&#39; for x in vals[:5]])
                                else:
                                        s += &#34;, &#34;.join([str(x) for x in vals[:5]])
                        else:
                                elms = []
                                for val in vals[:5]:
                                        elms.append(look(val))
                                s += &#34;, &#34;.join(elms)
                        if len(vals) &gt; 5:
                                s += &#34;, ...]&#34;
                        else:
                                s += &#34;]&#34;
                        return s

                s = look(self[:10])
                if len(s) &gt; 60:
                        return s[:56] + &#34; ···&#34;
                return s



        def __repr__(self) -&gt; str:
                return f&#34;&lt;Tensor {self.name} dtype=&#39;{self.dtype}&#39; dims={self.dims}, shape={self.shape}&gt;&#34;</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="shoji.tensor.Tensor.valid_types"><code class="name">var <span class="ident">valid_types</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="shoji.tensor.Tensor.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, vals: Union[List[numpy.ndarray], numpy.ndarray]) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append(self, vals: Union[List[np.ndarray], np.ndarray]) -&gt; None:
        assert self.wsm is not None, &#34;Cannot append to unbound tensor&#34;
        
        if self.rank == 0:
                raise ValueError(&#34;Cannot append to a scalar&#34;)
        if isinstance(self.dims[0], str):
                if self.wsm is not None:
                        d = self.wsm[self.dims[0]]
                        if isinstance(d, shoji.Dimension):
                                d.append(vals)
                                return
                raise ValueError(f&#34;Failed to append along named first dimension {self.dims[0]}&#34;)

        tv = TensorValue(vals)
        n_bytes = tv.size_in_bytes()
        n_batches = max(1, n_bytes // 5_000_000) # Should be plenty, given that we&#39;ll also be compressing the rows when writing
        n_rows_per_transaction = max(1, len(vals) // n_batches)
        ix: int = 0
        while ix &lt; len(vals):
                batch = {self.name: vals[ix: ix + n_rows_per_transaction]}
                shoji.io.append_tensors(self.wsm._db.transaction, self.wsm, self.name, batch)
                ix += n_rows_per_transaction</code></pre>
</details>
</dd>
<dt id="shoji.tensor.Tensor.numpy_dtype"><code class="name flex">
<span>def <span class="ident">numpy_dtype</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def numpy_dtype(self) -&gt; str:
        if self.dtype == &#34;string&#34;:
                return &#34;object&#34;
        return self.dtype</code></pre>
</details>
</dd>
<dt id="shoji.tensor.Tensor.python_dtype"><code class="name flex">
<span>def <span class="ident">python_dtype</span></span>(<span>self) ‑> Callable</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def python_dtype(self) -&gt; Callable:
        if self.dtype == &#34;string&#34;:
                return str
        if self.dtype == &#34;bool&#34;:
                return bool
        if self.dtype in (&#34;float16&#34;, &#34;float32&#34;, &#34;float64&#34;):
                return float
        return int</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="shoji.tensor.TensorValue"><code class="flex name class">
<span>class <span class="ident">TensorValue</span></span>
<span>(</span><span>values: Union[Tuple[numpy.ndarray], List[numpy.ndarray], numpy.ndarray])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TensorValue:
        def __init__(self, values: Union[Tuple[np.ndarray], List[np.ndarray], np.ndarray]) -&gt; None:
                self.values = values

                if isinstance(values, (list, tuple)):
                        self.jagged = True
                        self.rank = values[0].ndim + 1
                        self.dtype = values[0].dtype.name
                        if self.dtype == &#34;object&#34;:
                                self.dtype = &#34;string&#34;

                        shape: List[int] = list(values[0].shape)
                        for i, array in enumerate(values):
                                if not isinstance(array, np.ndarray):
                                        raise ValueError(&#34;Rows of jagged tensor must be numpy ndarrays&#34;)
                                if self.rank != array.ndim + 1:
                                        raise ValueError(&#34;Rows of jagged tensor cannot be mixed rank&#34;)
                                if self.dtype != array.dtype:
                                        raise ValueError(&#34;Rows of jagged tensor cannot be mixed dtype&#34;)
                                if self.dtype == &#34;string&#34;:
                                        if not all([isinstance(x, str) for x in array.flat]):
                                                raise TypeError(&#34;string tensors (numpy dtype=&#39;object&#39;) must contain only string elements&#34;)
                                if array.ndim != len(shape):
                                        raise ValueError(f&#34;Rank mismatch: shape {array.shape} of subarray at row {i} is not the same rank as shape {shape} at row 0&#34;)
                                for ix in range(len(shape)):
                                        if shape[ix] != array.shape[ix]:
                                                shape[ix] = 0
                        self.shape = tuple([len(values)] + shape)                       
                else:
                        self.jagged = False
                        self.rank = values.ndim
                        self.dtype = values.dtype.name
                        if self.dtype == &#34;object&#34;:
                                self.dtype = &#34;string&#34;
                                if not all([isinstance(x, str) for x in values.flat]):
                                        raise TypeError(&#34;string tensors (numpy dtype=&#39;object&#39;) must contain only string elements&#34;)
                        self.shape = values.shape

                if self.dtype not in Tensor.valid_types:
                        raise TypeError(f&#34;Invalid dtype &#39;{self.dtype}&#39; for tensor value&#34;)


        @property
        def size(self) -&gt; int:
                return np.prod(self.shape)

        def __len__(self) -&gt; int:
                if self.rank &gt; 0:
                        return self.shape[0]
                return 1
        
        def __iter__(self):
                for row in self.values:
                        yield row

        def size_in_bytes(self) -&gt; int:
                n_bytes = 0
                if not self.jagged:
                        if self.dtype == &#34;string&#34;:
                                n_bytes += sum([len(s) for s in self.values]) * 2
                        else:
                                n_bytes += self.values.size * self.values.itemsize  # type: ignore
                else:
                        for row in self.values:
                                if self.dtype == &#34;string&#34;:
                                        n_bytes += sum([len(s) for s in row]) * 2
                                else:
                                        n_bytes += row.size * row.itemsize
                return n_bytes</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="shoji.tensor.TensorValue.size"><code class="name">var <span class="ident">size</span> : int</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def size(self) -&gt; int:
        return np.prod(self.shape)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="shoji.tensor.TensorValue.size_in_bytes"><code class="name flex">
<span>def <span class="ident">size_in_bytes</span></span>(<span>self) ‑> int</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def size_in_bytes(self) -&gt; int:
        n_bytes = 0
        if not self.jagged:
                if self.dtype == &#34;string&#34;:
                        n_bytes += sum([len(s) for s in self.values]) * 2
                else:
                        n_bytes += self.values.size * self.values.itemsize  # type: ignore
        else:
                for row in self.values:
                        if self.dtype == &#34;string&#34;:
                                n_bytes += sum([len(s) for s in row]) * 2
                        else:
                                n_bytes += row.size * row.itemsize
        return n_bytes</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#overview">Overview</a><ul>
<li><a href="#rank">Rank</a></li>
<li><a href="#datatype">Datatype</a></li>
<li><a href="#dimensions">Dimensions</a></li>
<li><a href="#shape">Shape</a></li>
</ul>
</li>
<li><a href="#key-concept-rows">Key concept: rows</a></li>
<li><a href="#jagged-tensors">Jagged tensors</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="shoji" href="index.html">shoji</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="shoji.tensor.Tensor" href="#shoji.tensor.Tensor">Tensor</a></code></h4>
<ul class="">
<li><code><a title="shoji.tensor.Tensor.append" href="#shoji.tensor.Tensor.append">append</a></code></li>
<li><code><a title="shoji.tensor.Tensor.numpy_dtype" href="#shoji.tensor.Tensor.numpy_dtype">numpy_dtype</a></code></li>
<li><code><a title="shoji.tensor.Tensor.python_dtype" href="#shoji.tensor.Tensor.python_dtype">python_dtype</a></code></li>
<li><code><a title="shoji.tensor.Tensor.valid_types" href="#shoji.tensor.Tensor.valid_types">valid_types</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="shoji.tensor.TensorValue" href="#shoji.tensor.TensorValue">TensorValue</a></code></h4>
<ul class="">
<li><code><a title="shoji.tensor.TensorValue.size" href="#shoji.tensor.TensorValue.size">size</a></code></li>
<li><code><a title="shoji.tensor.TensorValue.size_in_bytes" href="#shoji.tensor.TensorValue.size_in_bytes">size_in_bytes</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>